{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww26860\viewh15620\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ## Project Readme\
## Project Overview\
\
This project aims to identify media manipulations on academic papers using extensive analysis based on their metadata, focusing on data preparation, feature extraction through web scraping and data manipulation, and employing similarity analysis and clustering techniques for data exploration.\
\
## Project Steps\
\
1. **Install tika-python and tika-similarity:**\
   - The project starts by installing `tika-python` and `tika-similarity` packages. These libraries allow text and metadata extraction from various file formats and facilitate document similarity analysis.\
\
2. **Install Required Packages:**\
   - Apart from `tika-python` and `tika-similarity`, other essential packages are installed. These include `pandas`, `sklearn`, `beautifulsoup`, `requests`, `googlesearch`, `Levenshtein`, `csv`, `selenium`, `chromedriver`, and more. These packages provide tools for data manipulation, web scraping, similarity analysis, and clustering. Installation and usage guide could be found at the end of this Readme file.\
\
3. **Web Scraping ResearchGate Website to form \'93bik_rg.csv\'94:**\
   - Web scraping techniques using `selenium` are utilized to extract additional information from the ResearchGate website. The data collected includes university affiliations and citation counts, which are added as additional features to form the second dataset, \'93bik_rg.csv\'94.\
\
4. **Web Scraping Wikipedia and UNDP Datasets:**\
   - Wikipedia is scraped to obtain information about the country and the world ranking associated with the universities from the second dataset, \'93bik_rg.csv\'94. Additionally, the UNDP dataset's human development index dataset is downloaded to extract relevant indices correlated with countries and years.\
\
5. **Integration of Data from Wikipedia and UNDP to form \'93bik_final.csv\'94 :**\
   - The information obtained from Wikipedia and the UNDP dataset is integrated with the \'93bik_rg.csv\'94, forming the final dataset, \'93bik_final.csv\'94 with additional features. This comprehensive dataset is ready for similarity analysis and clustering.\
\
6. **Cosine Similarity Analysis:**\
   - The `tika-similarity` library is used to calculate cosine similarity within the final dataset. This analysis generates a matrix of similarities (214x213) to explore relationships between academic papers based on metadata.\
\
7. **Edit Distance and Jaccard Similarity Analysis:**\
   - The `tika-similarity` library is applied to compute the edit distance and Jaccard similarity on all three datasets, resulting in three file-wise similarity scores for each method, totaling six scores.\
\
8. **Clustering with D3.js:**\
   - Utilizing the similarity scores obtained earlier, clustering is performed with `D3.js`, a JavaScript library for data visualization. The resulting visualizations offer insights into potential patterns and clusters within the data.\
\
9. **KNN Clustering and Feature Analysis:**\
   - Based on the clustering results from D3.js, `sklearn` is used for KNN clustering. This analysis helps determine which features contribute to forming the identified clusters, allowing for deeper exploration and potential answers to specific questions related to the data.\
\
10. **Additional Insights and Conclusion:**\
    - The project draws conclusions based on the analysis and interprets the results. It explores the potential for answering additional questions by adding new features and provides insights into media manipulations on academic papers based on their metadata.\
\
---\
Please review the revised project overview and steps. If there are any specific details you would like to add or modify, feel free to let me know, and I'll be happy to assist further.\
\
### Installation and Usage in addition to Tika-python and Tika-similarity\
\
\
#### ChromeDriver and Selenium\
- ChromeDriver: Automate Chrome browser interactions with ChromeDriver. Download the appropriate version for your Chrome browser (https://sites.google.com/a/chromium.org/chromedriver/downloads) and place the `chromedriver` executable in a directory listed in the system's PATH.\
\
- Selenium: Install Selenium for web automation and testing using the following pip command:\
  ```\
  pip install selenium\
  ```\
\
#### D3.js (Data-Driven Documents)\
D3.js is a JavaScript library for data visualization. Download D3.js from the official website (https://d3js.org/) and save the file in your project directory. Include D3.js in your HTML file as follows:\
```html\
<script src="d3.js"></script>\
```\
\
#### Levenshtein (Python-Levenshtein)\
For Levenshtein distance calculations, install Python-Levenshtein with the following pip command:\
```\
pip install python-Levenshtein\
```\
\
---\
}